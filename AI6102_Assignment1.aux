\relax 
\@writefile{toc}{\contentsline {paragraph}{1. Conditional Probabilities}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{2. Multiclass Negative Log Likelihood}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{3. Regularized Negative Log‐Likelihood}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{4. Gradient Computation}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{5. Gradient Descent Update}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{5. Prediction Rule}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1}Question 2 (5 marks)}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Download the a9a dataset \(\dots  \) Detailed information is available here.}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Regarding the linear kernel, show 3-fold cross-validation \(\dots  \) training set (in accuracy).}{3}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The 3‐fold cross‐validation results of varying values of $C$ in SVC with linear kernel on the a9a training set (in accuracy).}}{3}{}\protected@file@percent }
\newlabel{tab:linear‐cv‐linear}{{1}{3}{}{table.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Regarding the rbf kernel, show 3-fold \(\dots  \) Some examples can be found here.}{4}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces The 3‐fold cross‐validation results of varying values of $\gamma $ and $C$ in SVC with RBF kernel on the a9a training set (in accuracy).}}{4}{}\protected@file@percent }
\newlabel{tab:rbf-cv}{{2}{4}{}{table.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Based on the results shown in Tables \(\dots  \) the following table:}{4}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Test results of SVC on the a9a test set (in accuracy).}}{4}{}\protected@file@percent }
\newlabel{tab:test-results}{{3}{4}{}{table.3}{}}
\@writefile{toc}{\contentsline {paragraph}{1. The standard soft-margin SVM solves}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{2. Introduce the hinge loss}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{3. Empirical Risk Minimization}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{1. The primal objective is}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{2. Objective in Terms of \(alpha\) and Differentiation}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{3. Solving for \(\alpha \) yields the dual(kernel) closed form}{5}{}\protected@file@percent }
\gdef \@abspage@last{5}
